# smartm2m Custom Logging Library

통합로깅시스템을 위한 터미널에이전트전용 표준화된 Java 로깅 라이브러리입니다.

## 특징

- XML 설정 불필요 (jar 추가만으로 동작)
- 기존 로그 시스템 보존 (log4j.xml, logback.xml 그대로 유지)
- 선택적 Fluentd/Kafka 전송
- Java 6 ~ 11+ 지원
- log4j 1.2 / Logback 모두 지원
- 비동기 Kafka 전송 (성능 영향 없음)
- Thread-safe 보장

## 설치

### Maven

```xml
<dependency>
    <groupId>com.smartm2m</groupId>
    <artifactId>unified-logging</artifactId>
    <version>1.0.0</version>
</dependency>

<!-- Kafka Client (아직 없는 경우만) -->
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>0.9.0.0</version>
</dependency>
```

## 사용법

### 기본 사용

```java
import com.smartm2m.logging.CustomLogger;

public class MyService {
    private final CustomLogger logger = new CustomLogger(getClass());
    
    public void myMethod() {
        // 일반 로그 (기존 시스템만)
        logger.info("로그메시지");
        logger.error("에러 메시지");
        logger.warn("경고 메시지");
        logger.debug("디버그 메시지");
        
        // Fluentd 전송 (JSON만 stdout + 파일)
        logger.message("로그메시지")
            .context("컨텍스트키", 컨텍스트값)
            .info()
            .fluentd();  // JSON으로 변환하여 stdout + 파일에 저장
        
        // Fluentd 전송 (JSON만 stdout + 파일)
        logger.message("로그메시지")
            .context("컨텍스트키", 컨텍스트값)
            .info()
            .fluentd();  // JSON으로 변환하여 stdout + 파일에 저장
        
        // Kafka 전송 (기존 로그 + Kafka)
        logger.message("로그메시지")
            .context("컨텍스트키", 컨텍스트값)
            .info()
            .kafka();  // 자동으로 기존 로그도 남김
    }
}
```

### 로그 레벨

```java
// 기존 Logger처럼 직접 호출 (기존 로그만, Kafka 전송 없음)
logger.info("로그메시지");
logger.warn("로그메시지");
logger.error("로그메시지");
logger.debug("로그메시지");

// 빌더 패턴 (Kafka 전송 포함)
logger.message("로그메시지").info().kafka();
logger.message("로그메시지").warn().kafka();
logger.message("로그메시지").error().kafka();
logger.message("로그메시지").debug().kafka();

// 또는 level() 메서드 사용
logger.message("로그메시지").level("ERROR").kafka();
```

### 서비스 정보 설정

**방법 1: 환경변수 (권장)**

```bash
export SERVICE_TERMINAL=HJNC
export SERVICE_TYPE=tss
export SERVICE_NAME=payment-api
export SERVICE_ROLE=api
```

```java
// 코드에서 명시 안 해도 자동으로 환경변수 사용
logger.message("작업 완료").info().fluentd();
logger.message("작업 완료").info().kafka();
```

**방법 2: 코드에서 명시 (오버라이드)**

```java
logger.message("특수 작업")
    .terminal("터미널값")  // 환경변수 무시하고 이 값 사용
    .serviceType("서비스타입")
    .service("서비스이름")
    .role("역할")
    .info()
    .fluentd();  // 또는 .kafka()
```

**우선순위: 코드 명시 > 환경변수 > null**

### AutoContext

```java
Map<String, Object> data = new HashMap<String, Object>();
data.put("키", 값);

logger.message("로그메시지")
    .autoContext(data)  // traceId 자동 추출 + 모든 필드 포함
    .info()
    .kafka();
```

## 환경변수

### 필수 (서비스 정보)

```bash
SERVICE_TERMINAL=HJNC         # 터미널/IDC 식별자
SERVICE_TYPE=tss              # 서비스 타입
SERVICE_NAME=payment-api      # 서비스 이름
SERVICE_ROLE=api              # 역할
```

### 선택 (Kafka 설정, 기본값 있음)

```bash
KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092,kafka3:9092
KAFKA_TOPIC=bct-terminal-log
```

**기본값:**
- `KAFKA_BOOTSTRAP_SERVERS`: `133.186.213.152:39092,133.186.213.152:39093,133.186.213.152:39094`
- `KAFKA_TOPIC`: `uknown-terminal-log`

## JSON 출력 예시

```json
{
  "timestamp": 타임스탬프값,
  "message": "로그메시지",
  "level": "로그레벨",
  "thread_name": "스레드이름",
  "source_file": "클래스풀네임",
  "source_method": "메서드이름",
  "source_line": 라인번호,
  "terminal": "터미널값",
  "service_type": "서비스타입",
  "service": "서비스이름",
  "role": "역할",
  "컨텍스트키": "컨텍스트값",
  "trace_id": "traceId값",
  "data_raw": "{\"컨텍스트키\":\"컨텍스트값\"}"
}
```

## 마이그레이션 가이드

### 레거시 프로젝트 (Java 6 + Log4j)

**기존:**

```java
Logger logger = LoggerFactory.getLogger(getClass());
logger.info("로그메시지: " + 변수값);
```

**마이그레이션 방법 1: 직접 교체 (기존 로그만)**

```java
// Logger를 CustomLogger로 교체
CustomLogger logger = new CustomLogger(getClass());
logger.info("로그메시지: " + 변수값);  // 기존과 동일하게 사용
```

**마이그레이션 방법 2: Kafka 전송 추가 (선택적)**

```java
CustomLogger logger = new CustomLogger(getClass());

// 일반 로그 (기존과 동일)
logger.info("일반 로그");

// 중요 로그만 Fluentd 또는 Kafka 전송
logger.message("로그메시지")
    .context("컨텍스트키", 컨텍스트값)
    .info()
    .fluentd();  // 또는 .kafka()
```

### Spring Boot 프로젝트 (Java 11 + Logback)

동일한 방식으로 사용 가능합니다. 기존 logback.xml 설정은 그대로 유지됩니다.

## 동작 원리

### 직접 호출 메서드 (기존 로그만)

```java
logger.info("로그메시지");
logger.error("로그메시지");
logger.warn("로그메시지");
logger.debug("로그메시지");
```

- SLF4J Logger를 사용하여 기존 log4j.xml/logback.xml 설정대로 동작
- 기존 로그 시스템에 영향 없음
- Fluentd/Kafka 전송 없음

### 빌더 패턴 + .fluentd() 메서드 (Fluentd 전송)

```java
logger.message("로그메시지").info().fluentd();
```

1. **JSON 변환** - 로그 메시지를 JSON 형식으로 변환
2. **기존 로그 시스템에 JSON 출력** - stdout + 파일에 JSON 저장
3. **Fluentd 수집** - Fluentd가 stdout을 수집하여 중앙 로그 시스템으로 전송
4. **설정 변경 불필요** - 기존 로그 설정 그대로 사용

### 빌더 패턴 + .kafka() 메서드 (Kafka 전송)

```java
logger.message("로그메시지").info().kafka();
```

1. **자동으로 기존 로그 기록** - 기존 로그 시스템에 먼저 기록
2. **Kafka 전송** - 비동기로 JSON 형태로 Kafka에 전송
3. **에러 처리** - Kafka 전송 실패해도 애플리케이션은 계속 동작

## 프로젝트 구조

```
unified-logging/
├── pom.xml
├── README.md
└── src/
    └── main/
        └── java/
            └── com/smartm2m/logging/
                ├── CustomLogger.java          # 메인 로거
                ├── KafkaProducerManager.java  # Kafka Producer 관리 (싱글톤)
                ├── JsonFormatter.java         # JSON 변환
                └── TraceIdExtractor.java      # TraceId 추출
```

## 빌드 및 배포

```bash
# 컴파일
mvn clean compile

# 패키징 (JAR 생성)
mvn clean package

# 소스 JAR 포함 빌드
mvn clean package source:jar

# Nexus Repository에 배포
mvn clean deploy
```

## 트러블슈팅

### Kafka 연결 실패

- 환경변수 `KAFKA_BOOTSTRAP_SERVERS` 확인
- Kafka 전송 실패해도 애플리케이션은 계속 동작
- 기존 로그는 정상적으로 남음

### 서비스 정보 null

- 환경변수 `SERVICE_TERMINAL`, `SERVICE_TYPE` 등 설정 확인
- 또는 코드에서 `.terminal()`, `.serviceType()` 등으로 명시

### 컴파일 에러 (Kafka client)

- Java 6 환경에서는 Kafka client 0.9.0.0 이상 필요
- Java 7+ 환경에서는 최신 버전 사용 가능

---

**Version**: 1.0.0  
**Last Updated**: 2025-01-15
