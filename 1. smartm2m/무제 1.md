````markdown
# smartm2m Custom Logging Library - 완전 구현 코드 생성 요청

## 프로젝트 개요
10개 IDC에서 사용할 표준화된 Java 로깅 라이브러리의 **완전한 구현 코드**를 생성해주세요.
XML 설정 없이 Java 코드만으로 동작하며, 기존 로그 시스템을 보존합니다.

## 핵심 요구사항

### 1. 동작 원리
```java
public void kafka() {
    // ✅ 1단계: 기존 로그 시스템 자동 호출
    this.log();  // SLF4J Logger를 사용하여 기존 log4j.xml/logback.xml 설정대로 동작
    
    // ✅ 2단계: Kafka 전송 (비동기)
    try {
        String json = JsonFormatter.toJson(message, level, resolvedContext);
        kafkaManager.send(json);
    } catch (Exception e) {
        // Kafka 실패해도 애플리케이션 중단 안 함
    }
}
````

### 2. 설정 우선순위

**Kafka 설정 (기본값 있음):**

```
1. 환경변수: KAFKA_BOOTSTRAP_SERVERS
2. 기본값: "133.186.213.152:39092,133.186.213.152:39093,133.186.213.152:39094"

3. 환경변수: KAFKA_TOPIC
4. 기본값: "bct-terminal-log"
```

**서비스 정보 (기본값 없음 - null 반환):**

```
terminal:
  1. 빌더 패턴 .terminal("HJNC")
  2. 환경변수 SERVICE_TERMINAL
  3. null

service_type:
  1. 빌더 패턴 .serviceType("tss")
  2. 환경변수 SERVICE_TYPE
  3. null

service:
  1. 빌더 패턴 .service("payment-api")
  2. 환경변수 SERVICE_NAME
  3. null

role:
  1. 빌더 패턴 .role("api")
  2. 환경변수 SERVICE_ROLE
  3. null
```

### 3. 사용 예시

**기본 사용:**

```java
CustomLogger logger = new CustomLogger(PaymentService.class);

// 일반 로그 (기존 시스템만)
logger.log("Payment processing started")
    .context("orderId", "ORD-123")
    .info()
    .log();

// Kafka 전송 (기존 로그 + Kafka)
logger.log("Payment completed")
    .context("orderId", "ORD-123")
    .context("amount", 50000)
    .info()
    .kafka();  // 내부에서 자동으로 .log() 호출 후 Kafka 전송
```

**레벨 편의 메서드:**

```java
// 기존 방식
logger.log("Error occurred").level("ERROR").kafka();

// 편의 메서드
logger.log("Error occurred").error().kafka();
logger.log("Warning").warn().kafka();
logger.log("Info message").info().kafka();
logger.log("Debug info").debug().kafka();
```

**서비스 정보 명시:**

```java
// 환경변수 설정된 경우 - 자동 사용
logger.log("Normal operation").info().kafka();
// → terminal, service_type 등은 환경변수에서 자동 로드

// 특수한 경우 - 오버라이드
logger.log("Special terminal operation")
    .terminal("SPECIAL-IDC")  // 빌더 명시가 우선
    .context("operation", "backup")
    .info()
    .kafka();
```

**AutoContext 사용:**

```java
Map<String, Object> data = new HashMap<String, Object>();
data.put("pinNo", "12345");
data.put("terminal", "HJNC");
data.put("amount", 50000);

logger.log("Transaction completed")
    .autoContext(data)  // traceId 자동 추출 + 모든 필드 포함
    .info()
    .kafka();
```

## 프로젝트 구조

```
custom-logging/
├── pom.xml
├── README.md
└── src/
    └── main/
        └── java/
            └── com/smartm2m/logging/
                ├── CustomLogger.java          # 메인 로거
                ├── KafkaProducerManager.java  # Kafka Producer 관리 (싱글톤)
                ├── JsonFormatter.java         # JSON 변환
                └── TraceIdExtractor.java      # TraceId 추출
```

## 상세 구현 명세

### CustomLogger.java

```java
package com.smartm2m.logging;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.HashMap;
import java.util.Map;

/**
 * smartm2m Custom Logger
 * 
 * XML 설정 없이 Java 코드만으로 동작하는 로거.
 * 기존 로그 시스템을 보존하며 선택적으로 Kafka 전송을 추가합니다.
 * 
 * 사용 예시:
 * CustomLogger logger = new CustomLogger(MyClass.class);
 * logger.log("Payment completed").context("amount", 5000).info().kafka();
 */
public class CustomLogger {
    
    private static final String[] VALID_LEVELS = {"ERROR", "WARN", "INFO", "DEBUG"};
    
    private final Logger defaultLogger;
    private final KafkaProducerManager kafkaManager;
    private final String loggerName;
    
    /**
     * 생성자
     * @param clazz 로거를 생성할 클래스
     */
    public CustomLogger(Class clazz) {
        if (clazz == null) {
            throw new IllegalArgumentException("클래스는 null일 수 없습니다.");
        }
        this.loggerName = clazz.getName();
        this.defaultLogger = LoggerFactory.getLogger(clazz);
        this.kafkaManager = KafkaProducerManager.getInstance();
    }
    
    /**
     * 로그 빌더 생성
     * @param message 로그 메시지
     * @return LogBuilder 인스턴스
     */
    public LogBuilder log(String message) {
        if (message == null || message.trim().isEmpty()) {
            throw new IllegalArgumentException("로그 메시지는 null이거나 빈 문자열일 수 없습니다.");
        }
        return new LogBuilder(message.trim());
    }
    
    /**
     * LogBuilder 내부 클래스
     * 빌더 패턴으로 로그를 구성하고 전송 방식을 선택합니다.
     */
    public class LogBuilder {
        private final String message;
        private String level = "INFO";
        private final Map<String, Object> context = new HashMap<String, Object>();
        
        private LogBuilder(String message) {
            this.message = message;
        }
        
        // ========== 레벨 설정 (기존 방식) ==========
        
        /**
         * 로그 레벨 설정
         * @param level ERROR, WARN, INFO, DEBUG
         */
        public LogBuilder level(String level) {
            if (level == null || level.trim().isEmpty()) {
                throw new IllegalArgumentException("로그 레벨은 null이거나 빈 문자열일 수 없습니다.");
            }
            
            String upperLevel = level.trim().toUpperCase();
            boolean isValid = false;
            for (int i = 0; i < VALID_LEVELS.length; i++) {
                if (VALID_LEVELS[i].equals(upperLevel)) {
                    isValid = true;
                    break;
                }
            }
            
            if (!isValid) {
                throw new IllegalArgumentException("유효하지 않은 로그 레벨: " + level);
            }
            
            this.level = upperLevel;
            return this;
        }
        
        // ========== 레벨 편의 메서드 ==========
        
        /**
         * INFO 레벨 설정
         */
        public LogBuilder info() {
            this.level = "INFO";
            return this;
        }
        
        /**
         * WARN 레벨 설정
         */
        public LogBuilder warn() {
            this.level = "WARN";
            return this;
        }
        
        /**
         * ERROR 레벨 설정
         */
        public LogBuilder error() {
            this.level = "ERROR";
            return this;
        }
        
        /**
         * DEBUG 레벨 설정
         */
        public LogBuilder debug() {
            this.level = "DEBUG";
            return this;
        }
        
        // ========== 컨텍스트 설정 ==========
        
        /**
         * 일반 컨텍스트 추가
         * @param key 키
         * @param value 값
         */
        public LogBuilder context(String key, Object value) {
            if (key == null) {
                throw new IllegalArgumentException("컨텍스트 키는 null일 수 없습니다.");
            }
            this.context.put(key, value);
            return this;
        }
        
        /**
         * 여러 컨텍스트를 한 번에 추가
         * @param contexts 컨텍스트 맵
         */
        public LogBuilder contexts(Map<String, Object> contexts) {
            if (contexts != null) {
                for (Map.Entry<String, Object> entry : contexts.entrySet()) {
                    if (entry.getKey() != null) {
                        this.context.put(entry.getKey(), entry.getValue());
                    }
                }
            }
            return this;
        }
        
        // ========== 서비스 정보 설정 (우선순위 1) ==========
        
        /**
         * Terminal 설정
         * 우선순위: 빌더 명시 > 환경변수(SERVICE_TERMINAL) > null
         */
        public LogBuilder terminal(String terminal) {
            this.context.put("terminal", terminal);
            return this;
        }
        
        /**
         * Service Type 설정
         * 우선순위: 빌더 명시 > 환경변수(SERVICE_TYPE) > null
         */
        public LogBuilder serviceType(String serviceType) {
            this.context.put("service_type", serviceType);
            return this;
        }
        
        /**
         * Service 설정
         * 우선순위: 빌더 명시 > 환경변수(SERVICE_NAME) > null
         */
        public LogBuilder service(String service) {
            this.context.put("service", service);
            return this;
        }
        
        /**
         * Role 설정
         * 우선순위: 빌더 명시 > 환경변수(SERVICE_ROLE) > null
         */
        public LogBuilder role(String role) {
            this.context.put("role", role);
            return this;
        }
        
        // ========== AutoContext ==========
        
        /**
         * 자동 컨텍스트 추출
         * traceId를 자동으로 추출하고, 모든 필드를 컨텍스트에 추가합니다.
         * 
         * @param data 데이터 맵
         */
        public LogBuilder autoContext(Map<String, Object> data) {
            if (data == null) {
                return this;
            }
            
            // traceId 추출
            String traceId = TraceIdExtractor.extractTraceId(data);
            if (!traceId.isEmpty()) {
                this.context.put("trace_id", traceId);
            }
            
            // 모든 필드 추가
            for (Map.Entry<String, Object> entry : data.entrySet()) {
                if (entry.getKey() != null && entry.getValue() != null) {
                    this.context.put(entry.getKey(), entry.getValue());
                }
            }
            
            return this;
        }
        
        // ========== 전송 메서드 ==========
        
        /**
         * 기존 로그 시스템만 사용
         * SLF4J Logger를 통해 기존 log4j.xml/logback.xml 설정대로 동작
         */
        public void log() {
            writeToDefaultLogger();
        }
        
        /**
         * 기존 로그 + Kafka 전송
         * 1. 먼저 기존 로그 시스템 사용 (자동)
         * 2. 추가로 Kafka 전송 (비동기)
         * 
         * Kafka 전송 실패 시에도 애플리케이션은 중단되지 않습니다.
         */
        public void kafka() {
            // 1. 기존 로그 자동 호출
            this.log();
            
            // 2. Kafka 전송
            try {
                // 서비스 정보 해결 (빌더 명시 > 환경변수 > null)
                Map<String, Object> resolvedContext = resolveServiceInfo();
                
                // JSON 생성
                String json = JsonFormatter.toJson(
                    message, 
                    level, 
                    loggerName,
                    resolvedContext
                );
                
                // Kafka 전송 (비동기)
                kafkaManager.send(json);
                
            } catch (Exception e) {
                // Kafka 전송 실패해도 애플리케이션은 계속 동작
                defaultLogger.error("Kafka 로그 전송 실패: " + e.getMessage(), e);
            }
        }
        
        // ========== 내부 헬퍼 메서드 ==========
        
        /**
         * SLF4J Logger를 사용하여 기존 로그 시스템에 기록
         */
        private void writeToDefaultLogger() {
            if ("ERROR".equals(level)) {
                defaultLogger.error(message);
            } else if ("WARN".equals(level)) {
                defaultLogger.warn(message);
            } else if ("DEBUG".equals(level)) {
                defaultLogger.debug(message);
            } else {
                defaultLogger.info(message);
            }
        }
        
        /**
         * 서비스 정보 해결
         * 우선순위: 빌더 명시 > 환경변수 > null
         */
        private Map<String, Object> resolveServiceInfo() {
            Map<String, Object> resolved = new HashMap<String, Object>();
            
            // 기존 컨텍스트 복사
            resolved.putAll(context);
            
            // terminal 해결
            if (!context.containsKey("terminal")) {
                String terminal = System.getenv("SERVICE_TERMINAL");
                if (terminal != null && !terminal.isEmpty()) {
                    resolved.put("terminal", terminal);
                } else {
                    resolved.put("terminal", null);
                }
            }
            
            // service_type 해결
            if (!context.containsKey("service_type")) {
                String serviceType = System.getenv("SERVICE_TYPE");
                if (serviceType != null && !serviceType.isEmpty()) {
                    resolved.put("service_type", serviceType);
                } else {
                    resolved.put("service_type", null);
                }
            }
            
            // service 해결
            if (!context.containsKey("service")) {
                String service = System.getenv("SERVICE_NAME");
                if (service != null && !service.isEmpty()) {
                    resolved.put("service", service);
                } else {
                    resolved.put("service", null);
                }
            }
            
            // role 해결
            if (!context.containsKey("role")) {
                String role = System.getenv("SERVICE_ROLE");
                if (role != null && !role.isEmpty()) {
                    resolved.put("role", role);
                } else {
                    resolved.put("role", null);
                }
            }
            
            return resolved;
        }
    }
}
```

### KafkaProducerManager.java

```java
package com.smartm2m.logging;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

/**
 * Kafka Producer 관리 클래스 (싱글톤)
 * 
 * 비동기 Kafka 전송을 담당하며, 전송 실패 시에도 애플리케이션을 중단하지 않습니다.
 */
public class KafkaProducerManager {
    
    private static final Logger logger = LoggerFactory.getLogger(KafkaProducerManager.class);
    private static KafkaProducerManager instance;
    
    private final KafkaProducer<String, String> producer;
    private final String topic;
    
    /**
     * Private 생성자 (싱글톤 패턴)
     */
    private KafkaProducerManager() {
        // Kafka 설정 로드 (환경변수 > 기본값)
        String brokers = getEnvOrDefault(
            "KAFKA_BOOTSTRAP_SERVERS",
            "133.186.213.152:39092,133.186.213.152:39093,133.186.213.152:39094"
        );
        
        this.topic = getEnvOrDefault(
            "KAFKA_TOPIC",
            "bct-terminal-log"
        );
        
        // Kafka Producer 설정
        Properties props = new Properties();
        props.put("bootstrap.servers", brokers);
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("acks", "0");  // 최대 성능 (응답 기다리지 않음)
        props.put("retries", 3);
        props.put("compression.type", "snappy");
        props.put("batch.size", 16384);
        props.put("linger.ms", 100);
        props.put("buffer.memory", 33554432);
        
        this.producer = new KafkaProducer<String, String>(props);
        
        logger.info("KafkaProducerManager initialized: brokers={}, topic={}", brokers, topic);
    }
    
    /**
     * 싱글톤 인스턴스 반환 (Thread-safe)
     */
    public static synchronized KafkaProducerManager getInstance() {
        if (instance == null) {
            instance = new KafkaProducerManager();
        }
        return instance;
    }
    
    /**
     * Kafka로 메시지 전송 (비동기)
     * 
     * @param json JSON 로그 데이터
     */
    public void send(String json) {
        if (json == null || json.isEmpty()) {
            return;
        }
        
        try {
            ProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, json);
            
            // 비동기 전송 (콜백 포함)
            producer.send(record, new Callback() {
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception != null) {
                        // 전송 실패 로깅만 (애플리케이션 중단 안 함)
                        logger.error("Kafka 전송 실패: topic={}, message={}", 
                            topic, exception.getMessage());
                    }
                }
            });
            
        } catch (Exception e) {
            logger.error("Kafka 전송 중 예외 발생: " + e.getMessage(), e);
        }
    }
    
    /**
     * 환경변수 로드 (기본값 포함)
     */
    private static String getEnvOrDefault(String key, String defaultValue) {
        String value = System.getenv(key);
        return (value != null && !value.isEmpty()) ? value : defaultValue;
    }
    
    /**
     * Producer 종료 (JVM 종료 시 호출)
     */
    public void close() {
        if (producer != null) {
            try {
                producer.close();
                logger.info("KafkaProducer closed");
            } catch (Exception e) {
                logger.error("KafkaProducer 종료 중 오류: " + e.getMessage(), e);
            }
        }
    }
}
```

### JsonFormatter.java

```java
package com.smartm2m.logging;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import java.util.HashMap;
import java.util.Map;

/**
 * JSON 포맷 변환 클래스
 * 
 * 통일된 JSON 스키마로 변환하여 ClickHouse 적재를 용이하게 합니다.
 */
public class JsonFormatter {
    
    private static final Gson gson = new GsonBuilder()
        .disableHtmlEscaping()
        .create();
    
    /**
     * Private 생성자 (유틸리티 클래스)
     */
    private JsonFormatter() {
        throw new UnsupportedOperationException("Utility class");
    }
    
    /**
     * 로그 데이터를 JSON 문자열로 변환
     * 
     * @param message 로그 메시지
     * @param level 로그 레벨
     * @param loggerName 로거 이름 (클래스명)
     * @param context 컨텍스트 맵 (서비스 정보 포함)
     * @return JSON 문자열
     */
    public static String toJson(String message, String level, String loggerName, Map<String, Object> context) {
        Map<String, Object> logData = new HashMap<String, Object>();
        
        // 기본 필드
        logData.put("timestamp", System.currentTimeMillis());
        logData.put("message", message);
        logData.put("level", level);
        logData.put("thread_name", Thread.currentThread().getName());
        
        // 소스 정보
        logData.put("source_file", loggerName);
        
        // StackTrace에서 method, line 추출
        StackTraceElement[] stackTrace = Thread.currentThread().getStackTrace();
        if (stackTrace != null && stackTrace.length > 0) {
            // CustomLogger 호출 지점 찾기
            for (int i = 0; i < stackTrace.length; i++) {
                StackTraceElement element = stackTrace[i];
                String className = element.getClassName();
                
                // CustomLogger 관련 클래스가 아닌 첫 번째 호출자
                if (!className.startsWith("com.smartm2m.logging") 
                    && !className.startsWith("java.lang.Thread")) {
                    logData.put("source_method", element.getMethodName());
                    logData.put("source_line", element.getLineNumber());
                    break;
                }
            }
        }
        
        // 컨텍스트 추가 (서비스 정보 + 사용자 정의)
        if (context != null) {
            logData.putAll(context);
        }
        
        // data_raw 생성 (사용자 정의 컨텍스트만)
        Map<String, Object> dataRaw = new HashMap<String, Object>();
        if (context != null) {
            for (Map.Entry<String, Object> entry : context.entrySet()) {
                String key = entry.getKey();
                // 표준 필드는 제외
                if (!key.equals("terminal") 
                    && !key.equals("service_type")
                    && !key.equals("service")
                    && !key.equals("role")
                    && !key.equals("trace_id")) {
                    dataRaw.put(key, entry.getValue());
                }
            }
        }
        
        if (!dataRaw.isEmpty()) {
            logData.put("data_raw", gson.toJson(dataRaw));
        } else {
            logData.put("data_raw", "{}");
        }
        
        return gson.toJson(logData);
    }
}
```

### TraceIdExtractor.java

```java
package com.smartm2m.logging;

import java.util.Map;

/**
 * TraceId 추출 유틸리티
 * 
 * Fluentd의 traceId 추출 로직을 Java로 재현합니다.
 * 우선순위에 따라 여러 필드에서 traceId를 추출합니다.
 */
public class TraceIdExtractor {
    
    private static final String[] TRACE_ID_KEYS = {
        "traceId",
        "pinNo",
        "PINNO",
        "docKey",
        "DOCKEY"
    };
    
    /**
     * Private 생성자 (유틸리티 클래스)
     */
    private TraceIdExtractor() {
        throw new UnsupportedOperationException("Utility class");
    }
    
    /**
     * 맵에서 traceId 추출
     * 
     * @param record 데이터 맵
     * @return 추출된 traceId (없으면 빈 문자열)
     */
    public static String extractTraceId(Map<String, Object> record) {
        if (record == null || record.isEmpty()) {
            return "";
        }
        
        // 1. 최상위 레벨에서 traceId 검색
        Object traceId = record.get("traceId");
        if (traceId != null && !String.valueOf(traceId).trim().isEmpty()) {
            return String.valueOf(traceId);
        }
        
        // 2. data 필드에서 검색
        Object dataObj = record.get("data");
        if (dataObj instanceof Map) {
            Map<String, Object> data = (Map<String, Object>) dataObj;
            return extractFromData(data);
        }
        
        // 3. 최상위에서 다른 키들 검색
        for (int i = 1; i < TRACE_ID_KEYS.length; i++) {
            Object value = record.get(TRACE_ID_KEYS[i]);
            if (value != null && !String.valueOf(value).trim().isEmpty()) {
                return String.valueOf(value);
            }
        }
        
        return "";
    }
    
    /**
     * data 맵에서 우선순위대로 traceId 추출
     */
    private static String extractFromData(Map<String, Object> data) {
        if (data == null || data.isEmpty()) {
            return "";
        }
        
        for (int i = 0; i < TRACE_ID_KEYS.length; i++) {
            Object value = data.get(TRACE_ID_KEYS[i]);
            if (value != null) {
                String traceId = String.valueOf(value).trim();
                if (!traceId.isEmpty()) {
                    return traceId;
                }
            }
        }
        
        return "";
    }
}
```

### pom.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <groupId>com.smartm2m</groupId>
    <artifactId>unified-logging</artifactId>
    <version>1.0.0</version>
    <packaging>jar</packaging>
    
    <name>smartm2m Unified Logging Library</name>
    <description>Unified logging library for smartm2m projects with Kafka support</description>
    
    <properties>
        <java.version>1.6</java.version>
        <maven.compiler.source>1.6</maven.compiler.source>
        <maven.compiler.target>1.6</maven.compiler.target>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>
    
    <dependencies>
        <!-- SLF4J API (기존 프로젝트에 이미 있음) -->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>1.6.6</version>
            <scope>provided</scope>
        </dependency>
        
        <!-- Kafka Client (Java 6 호환 버전) -->
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>0.9.0.0</version>
        </dependency>
        
        <!-- Gson (Java 6 호환) -->
        <dependency>
            <groupId>com.google.code.gson</groupId>
            <artifactId>gson</artifactId>
            <version>2.8.0</version>
        </dependency>
    </dependencies>
    
    <!-- Nexus 배포 설정 -->
    <distributionManagement>
        <repository>
            <id>nexus-releases</id>
            <name>Nexus Release Repository</name>
            <url>http://your-nexus-server:8081/repository/maven-releases/</url>
        </repository>
        <snapshotRepository>
            <id>nexus-snapshots</id>
            <name>Nexus Snapshot Repository</name>
            <url>http://your-nexus-server:8081/repository/maven-snapshots/</url>
        </snapshotRepository>
    </distributionManagement>
    
    <build>
        <plugins>
            <!-- Compiler Plugin -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.1</version>
                <configuration>
                    <source>1.6</source>
                    <target>1.6</target>
                    <encoding>UTF-8</encoding>
                </configuration>
            </plugin>
            
            <!-- Source Plugin (소스 jar 생성) -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-source-plugin</artifactId>
                <version>2.4</version>
                <executions>
                    <execution>
                        <id>attach-sources</id>
                        <goals>
                            <goal>jar</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            
            <!-- JavaDoc Plugin -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-javadoc-plugin</artifactId>
                <version>2.10.3</version>
                <executions>
                    <execution>
                        <id>attach-javadocs</id>
                        <goals>
                            <goal>jar</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```

### README.md

````markdown
# smartm2m Custom Logging Library

10개 IDC에서 사용하는 표준화된 Java 로깅 라이브러리입니다.
XML 설정 없이 Java 코드만으로 동작하며, 기존 로그 시스템을 보존합니다.

## 특징

- ✅ XML 설정 불필요 (jar 추가만으로 동작)
- ✅ 기존 로그 시스템 보존 (log4j.xml, logback.xml 그대로 유지)
- ✅ 선택적 Kafka 전송
- ✅ Java 6 ~ 11+ 지원
- ✅ Log4j 1.2 / Logback 모두 지원
- ✅ 비동기 Kafka 전송 (성능 영향 없음)

## 설치

### Maven
```xml
<dependency>
    <groupId>com.smartm2m</groupId>
    <artifactId>custom-logging</artifactId>
    <version>1.0.0</version>
</dependency>

<!-- Kafka Client (아직 없는 경우만) -->
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>0.9.0.0</version>
</dependency>
````

## 사용법

### 기본 사용

```java
import com.smartm2m.logging.CustomLogger;

public class PaymentService {
    private final CustomLogger logger = new CustomLogger(PaymentService.class);
    
    public void processPayment(String orderId, int amount) {
        // 일반 로그 (기존 시스템만)
        logger.log("Payment processing started")
            .context("orderId", orderId)
            .info()
            .log();
        
        // Kafka 전송 (기존 로그 + Kafka)
        logger.log("Payment completed")
            .context("orderId", orderId)
            .context("amount", amount)
            .info()
            .kafka();  // 자동으로 기존 로그도 남김
    }
}
```

### 로그 레벨

```java
// 편의 메서드
logger.log("Info message").info().kafka();
logger.log("Warning").warn().kafka();
logger.log("Error occurred").error().kafka();
logger.log("Debug info").debug().kafka();

// 또는 기존 방식
logger.log("Message").level("ERROR").kafka();
```

### 서비스 정보 설정

**방법 1: 환경변수 (권장)**

```bash
export SERVICE_TERMINAL=HJNC
export SERVICE_TYPE=tss
export SERVICE_NAME=payment-api
export SERVICE_ROLE=api
```

```java
// 코드에서 명시 안 해도 자동으로 환경변수 사용
logger.log("작업 완료").info().kafka();
```

**방법 2: 코드에서 명시 (오버라이드)**

```java
logger.log("특수 작업")
    .terminal("SPECIAL-IDC")  // 환경변수 무시하고 이 값 사용
    .serviceType("batch")
    .service("special-service")
    .role("scheduler")
    .info()
    .kafka();
```

**우선순위: 코드 명시 > 환경변수 > null**

### AutoContext

```java
Map<String, Object> data = new HashMap<String, Object>();
data.put("pinNo", "12345");
data.put("amount", 50000);

logger.log("Transaction completed")
    .autoContext(data)  // traceId 자동 추출 + 모든 필드 포함
    .info()
    .kafka();
```

## 환경변수

### 필수 (서비스 정보)

```bash
SERVICE_TERMINAL=HJNC         # 터미널/IDC 식별자
SERVICE_TYPE=tss              # 서비스 타입
SERVICE_NAME=payment-api      # 서비스 이름
SERVICE_ROLE=api              # 역할
```

### 선택 (Kafka 설정, 기본값 있음)

```bash
KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092,kafka3:9092
KAFKA_TOPIC=bct-terminal-log
```

## JSON 출력 예시

```json
{
  "timestamp": 1705123456789,
  "message": "Payment completed",
  "level": "INFO",
  "thread_name": "http-nio-8080-exec-1",
  "source_file": "com.example.PaymentService",
  "source_method": "processPayment",
  "source_line": 42,
  "terminal": "HJNC",
  "service_type": "tss",
  "service": "payment-api",
  "role": "api",
  "orderId": "ORD-123",
  "amount": 50000,
  "trace_id": "12345",
  "data_raw": "{\"orderId\":\"ORD-123\",\"amount\":50000}"
}
```

## 마이그레이션 가이드

### 레거시 프로젝트 (Java 6 + Log4j)

**기존:**

```java
Logger logger = LoggerFactory.getLogger(MyService.class);
logger.info("Payment completed: " + orderId);
```

**마이그레이션 (선택적):**

```java
// 기존 logger 유지 (일반 로그)
Logger logger = LoggerFactory.getLogger(MyService.class);
logger.info("일반 로그");

// CustomLogger 추가 (중요 로그만 Kafka)
CustomLogger kafkaLogger = new CustomLogger(MyService.class);
kafkaLogger.log("Payment completed")
    .context("orderId", orderId)
    .info()
    .kafka();
```

## 배포

```bash
# Nexus에 배포
mvn clean deploy

# 다른 프로젝트에서 사용
# pom.xml에 dependency 추가만 하면 끝
```

## 트러블슈팅

### Kafka 연결 실패

- 환경변수 `KAFKA_BOOTSTRAP_SERVERS` 확인
- Kafka 전송 실패해도 애플리케이션은 계속 동작
- 기존 로그는 정상적으로 남음

### 서비스 정보 null

- 환경변수 `SERVICE_TERMINAL`, `SERVICE_TYPE` 등 설정 확인
- 또는 코드에서 `.terminal()`, `.serviceType()` 등으로 명시

### 성능 문제

- Kafka 전송은 비동기로 동작 (메인 스레드 블로킹 없음)
- 기존 로그 시스템에 영향 없음

## 라이선스

Copyright (c) 2025 smartm2m

```

## 추가 요청

1. **완전한 코드** - 주석 포함, 바로 컴파일 가능한 수준
2. **Java 6 호환** - 람다, Stream, diamond operator 없음
3. **에러 처리** - 모든 Kafka 관련 예외는 로깅만 (애플리케이션 중단 안 함)
4. **Thread-safe** - 싱글톤 동시성 보장
5. **JavaDoc** - 모든 public 메서드에 JavaDoc 주석

## 검증 체크리스트

생성된 코드가 다음을 만족하는지 확인:
- [ ] Java 6 문법만 사용
- [ ] .kafka() 호출 시 .log() 자동 호출
- [ ] 편의 메서드 .info(), .error() 등 구현
- [ ] 서비스 정보 우선순위 (코드 > 환경변수 > null)
- [ ] Kafka 설정 기본값 포함
- [ ] 비동기 Kafka 전송
- [ ] 예외 발생 시 애플리케이션 중단 안 됨
- [ ] Thread-safe 보장
- [ ] container_id, container_name 제거
- [ ] 컴파일 가능한 완전한 코드

---

위 명세에 맞춰 **완전한 구현 코드**를 생성해주세요.
```