
# 로그 중앙화 시스템 스택 정리

## 최종 스택

### 각 IDC (10개 터미널)
1. **커스텀 라이브러리** (Java - Log4j Wrapper)
2. **Filebeat**

### 중앙 서버
3. **Kafka**
4. **Kafka Connect** (ES Sink)
5. **Elasticsearch**
6. **Kibana** (관리자용)
7. **커스텀 UI** (개발자용)

---

## 선정 이유

| 스택 | 선정 이유 |
|------|----------|
| **커스텀 라이브러리** | • 터미널마다 다른 로깅 방식/용어 통일<br>• 공통 필드 표준화 + 원본 데이터 보존<br>• 기존 Log4j 영향 없음 |
| **Filebeat** | • 파일 → Kafka 전송의 표준 도구<br>• 경량 (10-50MB), 안정적<br>• 백프레셔 자동 처리 |
| **Kafka** | • 10개 IDC 로그의 중앙 버퍼<br>• ES 장애 시 로그 유실 방지<br>• 이미 운영 중 (추가 비용 없음) |
| **Kafka Connect** | • Kafka → ES 자동 전송 (코드 불필요)<br>• Logstash보다 경량/간단<br>• 표준화된 JSON이라 변환 불필요 |
| **Elasticsearch** | • 대용량 로그 검색/저장<br>• 역색인으로 빠른 조회<br>• 산업 표준 |
| **Kibana** | • ES 관리 및 모니터링<br>• 긴급 상황 백업 수단<br>• ES와 패키지로 제공 (거의 공짜) |
| **커스텀 UI** | • 개발자 친화적 인터페이스<br>• 컨테이너 추적에 특화<br>• 비즈니스 맥락 반영 |

---

## 전체 흐름

```
[각 IDC - 10곳]
  터미널 에이전트 (Java)
    → 커스텀 라이브러리 (표준 JSON 생성)
    → logs/dev-trace.log
    → Filebeat (파일 감시 및 전송)
         ↓
         
[중앙 서버]
    Kafka (메시지 버퍼)
    → Kafka Connect (자동 전송)
    → Elasticsearch (색인/저장)
    → Kibana (관리자 조회) + 커스텀 UI (개발자 조회)
```

---

## 핵심 특징

✅ **표준화**: 공통 필드로 통합 검색 가능  
✅ **유연성**: 원본 데이터 보존으로 터미널별 특수 정보 유지  
✅ **안정성**: Kafka 버퍼로 로그 유실 방지  
✅ **확장성**: 터미널 추가 시 라이브러리 + Filebeat만 설치  
✅ **운영 효율**: 코드 없는 구성 (Kafka Connect), 경량 스택